<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>A Detailed Example Â· Stochastic Frontier Analysis using Julia</title><script async src="https://www.googletagmanager.com/gtag/js?id=UA-134239283-1"></script><script>  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-134239283-1', {'page_path': location.pathname + location.search + location.hash});
</script><script data-outdated-warner src="assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.039/juliamono-regular.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="index.html"><img src="assets/logo.png" alt="Stochastic Frontier Analysis using Julia logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="index.html">Stochastic Frontier Analysis using Julia</a></span></div><form class="docs-search" action="search.html"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="index.html">Home of SFrontiers.jl</a></li><li><span class="tocitem">User Guide</span><ul><li><a class="tocitem" href="installation.html">Installation</a></li><li><a class="tocitem" href="overview.html">Estimation Overview</a></li><li class="is-active"><a class="tocitem" href="ex_detail.html">A Detailed Example</a></li><li><input class="collapse-toggle" id="menuitem-2-4" type="checkbox"/><label class="tocitem" for="menuitem-2-4"><span class="docs-label">Other Examples</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="ex_cross.html">cross-sectional models</a></li><li><a class="tocitem" href="ex_panel.html">panel models</a></li></ul></li><li><a class="tocitem" href="api.html">API Reference</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">User Guide</a></li><li class="is-active"><a href="ex_detail.html">A Detailed Example</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="ex_detail.html">A Detailed Example</a></li></ul></nav><div class="docs-right"><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h5 id="You-may-also-download-the-data-and-the-example-as-a-Jupyter-notebook-[in-a-zip-file](detailed_example.zip)."><a class="docs-heading-anchor" href="#You-may-also-download-the-data-and-the-example-as-a-Jupyter-notebook-[in-a-zip-file](detailed_example.zip).">You may also download the data and the example as a Jupyter notebook <a href="detailed_example.zip">in a zip file</a>.</a><a id="You-may-also-download-the-data-and-the-example-as-a-Jupyter-notebook-[in-a-zip-file](detailed_example.zip).-1"></a><a class="docs-heading-anchor-permalink" href="#You-may-also-download-the-data-and-the-example-as-a-Jupyter-notebook-[in-a-zip-file](detailed_example.zip)." title="Permalink"></a></h5><p>We use an example to go through the specification and estimation process of using <strong>SFrontiers</strong> in a stochastic frontier (SF) analysis. The example is a cross-sectional stochastic production frontier model with the <strong>normal and truncated-normal</strong> distribution assumptions. In addition, exogenous determinants are included in the model in the style of Wang (2002). We choose this elaborated model to showcase the features of <strong>SFrontiers</strong>.</p><ul><ul><ul><li><a href="ex_detail.html#detailedexample">Model Setup</a></li><ul><li><a href="ex_detail.html#goal-of-estimation">goal of estimation</a></li></ul><li><a href="ex_detail.html#:-Giving-Model-Specification-using-sfmodel_spec()">1: Giving Model Specification using <code>sfmodel_spec()</code></a></li><ul><li><a href="ex_detail.html#useDataFrame">using DataFrame data</a></li><li><a href="ex_detail.html#matrixinput">using matrix data (<em>alternative data input</em>)</a></li></ul><li><a href="ex_detail.html#:-Providing-Initial-Values-using-sfmodel_init()-*(optional)*">2: Providing Initial Values using <code>sfmodel_init()</code> <em>(optional)</em></a></li><li><a href="ex_detail.html#:-Choosing-Maximization-Options-(and-others)-using-sfmodel_opt()-*(optional)*">3: Choosing Maximization Options (and others) using <code>sfmodel_opt()</code> <em>(optional)</em></a></li><li><a href="ex_detail.html#:-Starting-Model-Maximization-using-sfmodel_fit()">4: Starting Model Maximization using <code>sfmodel_fit()</code></a></li><li><a href="ex_detail.html#:-Results-and-Post-Estimation-Analysis">5: Results and Post Estimation Analysis</a></li><ul><li><a href="ex_detail.html#.1-hypothesis-testing">5.1 hypothesis testing</a></li><li><a href="ex_detail.html#.2-inefficiency-and-efficiency-index">5.2 inefficiency and efficiency index</a></li><li><a href="ex_detail.html#.3-marginal-effects">5.3 marginal effects</a></li><li><a href="ex_detail.html#.4-bootstrapping-standard-errors-of-the-mean-marginal-effects">5.4 bootstrapping standard errors of the mean marginal effects</a></li><li><a href="ex_detail.html#.5-predicted-values-of-equations">5.5 predicted values of equations</a></li></ul><li><a href="ex_detail.html#.-save-results-to-disk">6. save results to disk</a></li></ul></ul></ul><h3 id="detailedexample"><a class="docs-heading-anchor" href="#detailedexample">Model Setup</a><a id="detailedexample-1"></a><a class="docs-heading-anchor-permalink" href="#detailedexample" title="Permalink"></a></h3><p>Consider the following setup:</p><p class="math-container">\[ \mathbf{y}  =  \mathbf{x} \beta + \mathbf{v} - \mathbf{u},\]</p><p>where <span>$\mathbf{y}$</span> is <span>$(N\times 1)$</span>, <span>$\mathbf{x}$</span> is <span>$(N\times k)$</span> and includes a column of 1 for intercept, and <span>$\beta$</span> is <span>$(k \times 1)$</span>. <span>$\mathbf{v}$</span> and <span>$\mathbf{u}$</span> are from random variables assumed to follow certain distribution assumptions. </p><p>We use <span>$x_i$</span> (which is (<span>$1 \times k$</span>)) to denote the <span>$i$</span>th observation of <span>$\mathbf{x}$</span>. Other notations follow similarly. The specification of the Wang (2002) model is thus:</p><p class="math-container">\[\begin{aligned}
 y_i &amp; = x_i \beta + \epsilon_i,\\
 \epsilon_i &amp; = v_i - u_i,\\
 v_i &amp; \sim N(0, \sigma_v^2),\\
 u_i &amp; \sim N^+(\mu, \sigma_u^2),\\
 \mu &amp; = z_i \delta \quad \mathrm{and} \quad \sigma_u^2  = \exp(z_i \gamma).
 \end{aligned}\]</p><p>Here, <span>$N^+(\mu, \sigma_u^2)$</span> denotes a <em>truncated normal distribution</em> obtained by truncating the normal distribution <span>$N(\mu, \sigma_u^2)$</span> from below at 0. The <span>$\mu$</span> and <span>$\sigma_u^2$</span> are thus the mean and the variance of the normal distribution <em>before</em> the truncation. <span>$z_i$</span> is a vector of exogenous determinants of inefficiency. Wang (2002) parameterizes both <span>$\mu$</span> and <span>$\sigma_u^2$</span> by the same vector of <span>$z_i$</span> while Battese and Coelli (1995) only parameterize <span>$\mu$</span>.</p><p>Note that the variance parameters <span>$\sigma_v^2$</span> and <span>$\sigma_u^2$</span> are parameterized using exponential functions to ensure positive values. In the case of <span>$\sigma_v^2$</span>,</p><p class="math-container">\[  \sigma_v^2 = \exp(c_v),\]</p><p>where <span>$c_v \in R$</span> is an unconstrained constant, and the log-likelihood maximization is w.r.t. <span>$c_v$</span> (among others).</p><h4 id="goal-of-estimation"><a class="docs-heading-anchor" href="#goal-of-estimation">goal of estimation</a><a id="goal-of-estimation-1"></a><a class="docs-heading-anchor-permalink" href="#goal-of-estimation" title="Permalink"></a></h4><p>Our goals of the model estimation include:</p><ul><li>estimate model parameters <span>$\{\beta, \delta, \gamma, \sigma_v^2  \}$</span>,</li><li>compute the inefficiency index <span>$E[u_i | \epsilon_i]|_{\epsilon_i =\hat{\epsilon}_i}$</span> and the efficiency index <span>$E[\exp(-u_i) | \epsilon_i]|_{\epsilon_i =\hat{\epsilon}_i}$</span> at the observation level,</li><li>calculate the marginal effect of <span>$z_i$</span> on <span>$E(u_i)$</span>.</li></ul><h3 id=":-Giving-Model-Specification-using-sfmodel_spec()"><a class="docs-heading-anchor" href="#:-Giving-Model-Specification-using-sfmodel_spec()">1: Giving Model Specification using <code>sfmodel_spec()</code></a><a id=":-Giving-Model-Specification-using-sfmodel_spec()-1"></a><a class="docs-heading-anchor-permalink" href="#:-Giving-Model-Specification-using-sfmodel_spec()" title="Permalink"></a></h3><p>We use the production data from paddy farmers in India as an empirical example. The <span>$\mathbf{y}$</span> is the annual rice production and <span>$\mathbf{x}$</span> is a vector of agricultural inputs. </p><p>There are two ways to provide data to <strong>Sfmodel</strong> for estimation. One is to use data from a <a href="https://dataframes.juliadata.org/stable/">DataFrame</a> where column names of the data are variable names. The other is to use data from matrices or vectors. The latter is the likely scenario in simulation studies where we generate data matrices and feed them to the model. Different ways of providing data would require slightly different specifications of <code>sfmodel_spec()</code>. </p><p>Since the farmers data is formatted, it is natural to use the <a href="https://dataframes.juliadata.org/stable/">DataFrame</a> approach. We will <a href="ex_detail.html#matrixinput">show the matrix approach</a> later.</p><h4 id="useDataFrame"><a class="docs-heading-anchor" href="#useDataFrame">using DataFrame data</a><a id="useDataFrame-1"></a><a class="docs-heading-anchor-permalink" href="#useDataFrame" title="Permalink"></a></h4><p>Our farmers dataset is in the <code>.csv</code> format, and we read it in using the <a href="https://csv.juliadata.org/stable/">CSV</a> package and save it as a <a href="https://dataframes.juliadata.org/stable/">DataFrame</a> with the name <code>df</code>.</p><pre><code class="language-julia hljs">julia&gt; using SFrontiers        # main packages
julia&gt; using DataFrames, CSV   # handling data

julia&gt; df = CSV.read(&quot;sampledata.csv&quot;, DataFrame; header=1, delim=&quot;,&quot;);
julia&gt; df[!, :_cons] .= 1.0;         # append column _cons as a column of 1 </code></pre><p>We append a column of 1 to <code>df</code> with the column name <code>_cons</code>. Adding this constant variable to the dataset is essential because we will use it to estimate constant parameters; more on this later. Before estimation, users should ensure that the data in <code>df</code> has been cleaned, i.e., it contains no missing values or any anomaly that may affect the estimation.</p><p>Let&#39;s see what is in the data.</p><pre><code class="language-julia hljs">julia&gt; describe(df)   # summary statistics
11Ã7 DataFrame
 Row â variable  mean       min       median    max       nmissing  eltype   
     â Symbol    Float64    Real      Float64   Real      Int64     DataType 
ââââââ¼âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ
   1 â yvar       7.27812    3.58666   7.28586   9.80335         0  Float64  
   2 â Lland      1.05695   -1.60944   1.14307   3.04309         0  Float64
   3 â PIland     0.146997   0.0       0.0       1.0             0  Float64
   4 â Llabor     6.84951    3.2581    6.72263   9.46622         0  Float64
   5 â Lbull      5.64161    2.07944   5.68358   8.37008         0  Float64
   6 â Lcost      4.6033     0.0       5.1511    8.73311         0  Float64
   7 â yr         5.38007    1         5.0      10               0  Int64
   8 â age       53.8856    26        53.0      90               0  Int64
   9 â school     2.02583    0         0.0      10               0  Int64
  10 â yr_1       5.38007    1         5.0      10               0  Int64
  11 â _cons      1.0        1         1.0       1               0  Int64</code></pre><p>Now we give model information to <strong>SFrontiers</strong> using <code>sfmodel_spec()</code>. Before we start: I take advantage of Julia&#39;s support of <a href="https://docs.julialang.org/en/v1/manual/unicode-input/">unicode characters</a> and use a few math symbols in <code>SFrontiers</code> functions. They are not difficult to use, and they help to match codes to models in papers thus making the code easier to understand. Nevertheless, I provide ascii alias of those symbols that can be used as alternatives.</p><p>This function generates a (global) dictionary that is automatically remembered and used in subsequent commands. The following specification indicates a Wang (2002) type of model, i.e., one that has a truncated normal distribution on <span>$u_i$</span> and both <span>$\mu$</span> and <span>$\sigma_u^2$</span> are parameterized by a vector of variables.</p><pre><code class="language-julia hljs">julia&gt; sfmodel_spec(sftype(prod), sfdist(trun),
                    @depvar(yvar),
                    @frontier(Lland, PIland, Llabor, Lbull, Lcost, yr, _cons),
                    @Î¼(age, school, yr, _cons),
                    @Ïáµ¤Â²(age, school, yr, _cons),
                    @Ïáµ¥Â²(_cons), message = true);</code></pre><ul><li><code>sftype(prod)</code> indicates a production-frontier type of model. The alternative is <code>cost</code> for cost frontier where the composed error is <span>$v_i + u_i$</span>.</li><li><code>sfdist(trun)</code> specifies the truncated-normal distribution assumption on <span>$u_i$</span>. Alternatives include <code>half</code>, <code>expo</code>, and <code>trun_scaling</code>.</li><li><code>@depvar(.)</code> specifies the dependent variable.</li><li><code>@frontier(.)</code> specifies the list of variables used in the frontier equation (i.e., the data of <span>$\mathbf{x}$</span>). The variables are assumed to be linear in the equation.</li><li><code>@Î¼(.)</code> (or <code>@mu(.)</code>) specifies the variables of inefficiency determinants as a linear function in <code>Î¼</code>.</li><li><code>@Ïáµ¤Â²(.)</code> (or <code>@sigma_u_2(.)</code>) and <code>@Ïáµ¥Â²(.)</code> (or <code>@sigma_v_2(.)</code>) specify the variables to parameterize the variances. Here we include only the variable <code>_cons</code> in <span>$\sigma_v^2$</span> so it is estimated as a constant.</li><li><code>message</code> determines whether to print the confirmation message of &quot;<code>A dictionary from ...</code>&quot;. The default is <code>false</code>.</li></ul><p>Note how the constant parameter <span>$\sigma_v^2$</span> is estimated. Recall the programming trick of using <span>$\sigma_v^2 = \exp(c_v)$</span> in the likelihood function. Here, <span>$c_v$</span> is simply the coefficient of the <code>_cons</code> variable. </p><div class="admonition is-success"><header class="admonition-header">Note on intercepts and constant parameters</header><div class="admonition-body"><p><strong>SFrontiers</strong> estimates intercepts and constant parameters as the coefficients of a constant variable. That is, if a parameter is constant, <strong>SFrontiers</strong> requires a variable with values equal to 1. It is true for all equations. </p></div></div><h4 id="matrixinput"><a class="docs-heading-anchor" href="#matrixinput">using matrix data (<em>alternative data input</em>)</a><a id="matrixinput-1"></a><a class="docs-heading-anchor-permalink" href="#matrixinput" title="Permalink"></a></h4><p>As aforementioned, data for estimation could also come from matrix and vectors, though the syntax of <code>sfmodel_spec()</code> is slightly different. The following code snippet has a simple example where we generate data in matrix for a normal half-normal model, and use them in <code>sfmodel_spec()</code>. The number of observations is 300.</p><blockquote><pre><code class="language-julia hljs">using SFrontiers, Random, Distributions

cons, x, v = ones(300,1), [randn(300, 2) ones(300,1)], randn(300,1)    

disTN = TruncatedNormal(0.0, 1.0, 0.0, Inf)    # half-normal dist with std dev = 1
u = rand(disTN, (300,1))                       # draw from half-normal r.v. 

y = x*ones(3)*0.5 .+ v .- u

sfmodel_spec(sftype(prod),  sfdist(half),   
            depvar(y),  frontier(x),  Ïáµ¤Â²(cons),  Ïáµ¥Â²(cons))</code></pre></blockquote><p>Note that the only difference in the syntax is using the function type of equation names (e.g., <code>depvar()</code>) instead of the macro type names (e.g., <code>@depvar()</code>). The rest of the estimation procedures are the same.</p><div class="admonition is-success"><header class="admonition-header">Note on `@depvar( )` vs. `depvar( )`</header><div class="admonition-body"><p>Macro type of equation names (<code>@depvar()</code>, <code>@frontier()</code>, <code>@Î¼()</code>, etc.) are used only when the arguments are column names from <a href="https://dataframes.juliadata.org/stable/">DataFrames</a>. For everything else, function type of equation names (<code>depvar()</code>, <code>frontier()</code>, <code>Î¼()</code>, etc.) are used.</p></div></div><h3 id=":-Providing-Initial-Values-using-sfmodel_init()-*(optional)*"><a class="docs-heading-anchor" href="#:-Providing-Initial-Values-using-sfmodel_init()-*(optional)*">2: Providing Initial Values using <code>sfmodel_init()</code> <em>(optional)</em></a><a id=":-Providing-Initial-Values-using-sfmodel_init()-*(optional)*-1"></a><a class="docs-heading-anchor-permalink" href="#:-Providing-Initial-Values-using-sfmodel_init()-*(optional)*" title="Permalink"></a></h3><p>Providing initial values is helpful in many cases though it is optional. You could skip it entirely or provide initial values only to a partial list of the equations. If missing (all or part of the equations), default values will be used. Currently, the default uses the OLS estimates as initial values for coefficients in <code>frontier()</code> and <span>$0.1$</span> for all other parameters. Here we use a mixed strategy in this example.</p><pre><code class="language-julia hljs">julia&gt; b_ini = ones(4)*(0.1)                      # a 4x1 vector of 0.1

julia&gt; sfmodel_init(  # frontier(bb),             # skip and use default
                    Î¼(b_ini),                     # as a vector
                    Ïáµ¤Â²(-0.1, -0.1, -0.1, -0.1),  # manually input the vector
                    Ïáµ¥Â²(-0.1) )                   # scalar</code></pre><ul><li>The order of equations in <code>sfmodel_init()</code> is not important. You can put <code>Î¼()</code> before or after <code>Ïáµ¥Â²()</code>, it does not matter.</li><li>The function type of equation names (e.g., <code>frontier()</code>, <code>Î¼()</code>, etc.) are used in <code>sfmodel_init()</code>.</li><li>Initial values specified in <code>Ïáµ¥Â²()</code> is w.r.t. the <span>$c_v$</span> as in <span>$\sigma_v^2 = \exp(c_v)$</span>. Put differently, the initial value is w.r.t. <span>$\log(\sigma_v^2)$</span>. If we put <code>Ïáµ¥Â²(-0.1)</code>, it means we have in mind the initial value of <span>$\sigma_v^2$</span> being <span>$\exp(-0.1) = 0.905$</span>.</li></ul><div class="admonition is-success"><header class="admonition-header">Note on name conflict</header><div class="admonition-body"><p><strong>SFrontiers</strong> uses names such as <code>Î¼</code>, <code>Ïáµ¥Â²</code>, <code>gamma</code>, <code>depvar</code>, <code>frontier</code>, etc.. If the names were used elsewhere in the program for different purposes (for instance, using <code>Î¼</code> to denote the value of a parameter), or users import other packages that use the same names, the name conflicts would arise. Signs of the problem include error messages such as </p><pre><code class="nohighlight hljs">MethodError: objects of type ... are not callable</code></pre><p>There are simple ways to workaround:</p><ul><li>Use fully qualified names. For instance, use <code>SFrontiers.Ïáµ¥Â²</code> instead of <code>Ïáµ¥Â²</code>.</li><li>Use an alias if there is one. For instance, use <code>sigma_v_2</code> instead of <code>Ïáµ¥Â²</code>. Check out the section of <code>API Reference</code> for more information.</li></ul></div></div><h3 id=":-Choosing-Maximization-Options-(and-others)-using-sfmodel_opt()-*(optional)*"><a class="docs-heading-anchor" href="#:-Choosing-Maximization-Options-(and-others)-using-sfmodel_opt()-*(optional)*">3: Choosing Maximization Options (and others) using <code>sfmodel_opt()</code> <em>(optional)</em></a><a id=":-Choosing-Maximization-Options-(and-others)-using-sfmodel_opt()-*(optional)*-1"></a><a class="docs-heading-anchor-permalink" href="#:-Choosing-Maximization-Options-(and-others)-using-sfmodel_opt()-*(optional)*" title="Permalink"></a></h3><p>The main purpose of this function is to choose options for the numerical maximization process, including the choice of optimization algorithms, the maximum number of iterations, the convergence criterion, and others. <strong>SFrontiers</strong> uses Julia&#39;s <a href="https://julianlsolvers.github.io/Optim.jl/stable/">Optim</a> package to do the maximization, though only a subset of <a href="https://julianlsolvers.github.io/Optim.jl/stable/">Optim</a>&#39;s options are directly accessible through <code>sfmodel_opt()</code>.</p><p>An effective estimation strategy for challenging optimization problems is to use a non-gradient algorithm in the first stage (<code>warmstart</code>) for a few iterations and then switch to gradient-based algorithms in the second stage (<code>main</code>) for speed and accuracy. <strong>SFrontiers</strong> uses the two-step strategy by default.</p><p>This function is also optional. All or part of the specifications may be skipped. If missing, default values will be used. The following example uses the default values.</p><pre><code class="language-julia hljs">julia&gt; sfmodel_opt(warmstart_solver(NelderMead()),   
                   warmstart_maxIT(400),
                   main_solver(Newton()), 
                   main_maxIT(2000), 
                   tolerance(1e-8))</code></pre><ul><li><code>warmstart_solver(NelderMead())</code>: specifies the <code>Nelder-Mead</code> algorithm (which is gradient-free) in the first stage estimation. Mind the braces &quot;<code>()</code>&quot; which is part of the algorithm name. Using a non-gradient algorithm in the first stage is recommended.</li><li><code>main_solver(Newton())</code>: specifies the <code>Newton</code> method (which uses 2nd derivatives, i.e., Hessian) in the second stage estimation. </li><li><code>warmstart_maxIT(400)</code> and <code>main_maxIT(2000)</code>: the maximum numbers of iterations in the first and the second stage estimation.</li><li><code>tolerance(1e-8)</code>: set the convergence criterion concerning the absolute tolerance in the gradient to <code>1e-8</code>. For non-gradient algorithms, it controls the main convergence tolerance, which is solver-specific. This is a wrapper of <a href="https://julianlsolvers.github.io/Optim.jl/stable/">Optim</a>&#39;s <code>g_tol</code> option.</li></ul><p>If the two-stage strategy is not desired, we can skip the <code>warmstart</code> stage by giving empty keyword values to the first stage options, such as <code>warmstart_solver()</code> or <code>warmstart_maxIT()</code>, or both. Note that if we skip the keywords (i.e., missing <code>warmstart_solver</code> or <code>warmstart_maxIT</code> entirely), the default will be reinstated. Again, the first stage estimation will only be skipped when empty values are explicitly given to the related options.</p><p>In addition to controlling the maximization procedures, <code>sfmodel_opt()</code> also provides options to control other things. They and their default values are the follows. </p><ul><li><code>table_format(text)</code>: specify the format to print coefficient tables on the screen after <code>sfmodel_fit()</code> is run. The choices include <code>text</code>, <code>html</code> (good for web-based notebooks such as Jupyter, Pluto), and <code>latex</code>.</li><li><code>banner(true)</code>: show banner to help visually identify the start of the estimation. </li><li><code>verbose(true)</code>: show interim and final results.</li><li><code>ineff_index(true)</code>: compute the Jondrow et al. (1982) inefficiency index and the Battese and Coelli (1987) efficiency index.</li><li><code>marginal(true)</code>: calculate the marginal effect of the inefficiency determinants (if any) on the unconditional mean of inefficiency.</li></ul><p>Turning the above options to <code>false</code> may sometimes be desirable, particularly in simulation settings.</p><h3 id=":-Starting-Model-Maximization-using-sfmodel_fit()"><a class="docs-heading-anchor" href="#:-Starting-Model-Maximization-using-sfmodel_fit()">4: Starting Model Maximization using <code>sfmodel_fit()</code></a><a id=":-Starting-Model-Maximization-using-sfmodel_fit()-1"></a><a class="docs-heading-anchor-permalink" href="#:-Starting-Model-Maximization-using-sfmodel_fit()" title="Permalink"></a></h3><p>Previous steps prepare the model, and now we are ready to estimate it. We use <code>sfmodel_fit()</code> to start the estimation, and it returns a dictionary containing <strong>coefficient estimates</strong>, <strong>efficiency and inefficiency index</strong>, <strong>marginal effects of inefficiency determinants</strong>, and other information of the model. In the following example, we save the returned dictionary in <code>res</code>.</p><pre><code class="language-julia hljs">julia&gt; res = sfmodel_fit(useData(df))  # df is the DataFrame</code></pre><ul><li><code>useData(df)</code>: name of the DataFrame <a href="ex_detail.html#useDataFrame">used in the 1st step</a>.</li><li>If the estimation data is <a href="ex_detail.html#matrixinput">from matrix and vectors</a>, the <code>useData()</code> option should be omitted. That is, we would do <code>res = sfmodel_fit()</code>.</li></ul><h3 id=":-Results-and-Post-Estimation-Analysis"><a class="docs-heading-anchor" href="#:-Results-and-Post-Estimation-Analysis">5: Results and Post Estimation Analysis</a><a id=":-Results-and-Post-Estimation-Analysis-1"></a><a class="docs-heading-anchor-permalink" href="#:-Results-and-Post-Estimation-Analysis" title="Permalink"></a></h3><p>Main results of the estimation will be shown on the screen after it is done. Let&#39;s see what we have.</p><pre><code class="nohighlight hljs">*********************************
       Estimation Results:
*********************************
Model type: the non-monotonic model of Wang (2002, JPA), normal and truncated-normal
Number of observations: 271
Number of total iterations: 153
Converged successfully: true
Log-likelihood value: -82.02573

ââââââââââââ¬âââââââââ¬ââââââââââ¬âââââââââââ¬âââââââââââ¬âââââââââ¬ââââââââââ¬ââââââââââ
â          â   Var. â   Coef. â Std.Err. â        z â  P&gt;|z| â 95%CI_l â 95%CI_u â
ââââââââââââ¼âââââââââ¼ââââââââââ¼âââââââââââ¼âââââââââââ¼âââââââââ¼ââââââââââ¼ââââââââââ¤
â frontier â  Lland â  0.2582 â   0.0725 â   3.5607 â 0.0004 â  0.1161 â  0.4003 â
â          â PIland â  0.1717 â   0.1761 â   0.9751 â 0.3304 â -0.1734 â  0.5169 â
â          â Llabor â  1.1658 â   0.0840 â  13.8805 â 0.0000 â  1.0012 â  1.3304 â
â          â  Lbull â -0.4215 â   0.0596 â  -7.0668 â 0.0000 â -0.5384 â -0.3046 â
â          â  Lcost â  0.0142 â   0.0128 â   1.1087 â 0.2686 â -0.0109 â  0.0394 â
â          â     yr â  0.0183 â   0.0095 â   1.9227 â 0.0556 â -0.0004 â  0.0369 â
â          â  _cons â  1.5429 â   0.3578 â   4.3123 â 0.0000 â  0.8417 â  2.2442 â
â        Î¼ â    age â -0.0479 â   0.0303 â  -1.5804 â 0.1153 â -0.1073 â  0.0115 â
â          â school â -0.2143 â   0.1711 â  -1.2523 â 0.2116 â -0.5497 â  0.1211 â
â          â     yr â  0.1480 â   0.1248 â   1.1853 â 0.2370 â -0.0967 â  0.3926 â
â          â  _cons â  1.0418 â   0.7283 â   1.4305 â 0.1538 â -0.3856 â  2.4693 â
â  log_Ïáµ¤Â² â    age â  0.0256 â   0.0096 â   2.6660 â 0.0082 â  0.0068 â  0.0445 â
â          â school â  0.1141 â   0.0569 â   2.0055 â 0.0460 â  0.0026 â  0.2256 â
â          â     yr â -0.2256 â   0.0496 â  -4.5507 â 0.0000 â -0.3228 â -0.1284 â
â          â  _cons â -1.1399 â   0.8904 â  -1.2803 â 0.2016 â -2.8850 â  0.6052 â
â  log_Ïáµ¥Â² â  _cons â -3.2667 â   0.2623 â -12.4556 â 0.0000 â -3.7808 â -2.7527 â
ââââââââââââ´âââââââââ´ââââââââââ´âââââââââââ´âââââââââââ´âââââââââ´ââââââââââ´ââââââââââ

Convert the constant log-parameter to its original scale, e.g., ÏÂ² = exp(log_ÏÂ²):
âââââââ¬âââââââââ¬âââââââââââ
â     â  Coef. â Std.Err. â
âââââââ¼âââââââââ¼âââââââââââ¤
â Ïáµ¥Â² â 0.0381 â   0.0100 â
âââââââ´âââââââââ´âââââââââââ

Table format: text. Use sfmodel_opt() to choose between text, html, and latex.

***** Additional Information *********
* OLS (frontier-only) log-likelihood: -104.96993
* Skewness of OLS residuals: -0.70351
* The sample mean of the JLMS inefficiency index: 0.33416
* The sample mean of the BC efficiency index: 0.7462

* The sample mean of inefficiency determinants&#39; marginal effects on E(u): (age = -0.00264, school = -0.01197, yr = -0.0265)
* Marginal effects of the inefficiency determinants at the observational level are saved in the return. See the follows.

* Use `name.list` to see saved results (keys and values) where `name` is the return specified in `name = sfmodel_fit(..)`. Values may be retrieved using the keys. For instance:
   ** `name.loglikelihood`: the log-likelihood value of the model;
   ** `name.jlms`: Jondrow et al. (1982) inefficiency index;
   ** `name.bc`: Battese and Coelli (1988) efficiency index;
   ** `name.marginal`: a DataFrame with variables&#39; (if any) marginal effects on E(u).
* Use `keys(name)` to see available keys.
**************************************</code></pre><p>As reminded in the printout, all of the shown statistics and many of the other model information are saved in the dictionary which can be called later for further investigation. We have saved it in <code>res</code>. Let&#39;s see the list of available keys.</p><pre><code class="language-julia hljs">julia&gt; keys(res)      # keywords in res
(:converged, :iter_limit_reached, :_______________, :n_observations, :loglikelihood, :table, :coeff, :std_err, :var_cov_mat, :jlms, :bc, :OLS_loglikelihood, :OLS_resid_skew, :marginal, :marginal_mean, :_____________, :model, :depvar, :frontier, :Î¼, :ÏâÂ², :Ïáµ¤Â², :Ïáµ¥Â², :log_ÏâÂ², :log_Ïáµ¤Â², :log_Ïáµ¥Â², :type, :dist, :PorC, :timevar, :idvar, :table_format, :modelid, :verbose, :hasDF, :transfer, :coeff_frontier, :coeff_Î¼, :coeff_log_Ïáµ¤Â², :coeff_log_Ïáµ¥Â², :________________, :Hessian, :gradient_norm, :actual_iterations, :______________, :warmstart_solver, :warmstart_ini, :warmstart_maxIT, :main_solver, :main_ini, :main_maxIT, :tolerance, :eqpo, :redflag, :list)</code></pre><p>Among the keywords is the term <code>:coeff</code>, which indicates the saved coefficient vector. We may retrieve the coefficient vector using <code>res.coeff</code> and save it in the name <code>b0</code> possibly for later use.</p><pre><code class="language-julia hljs">julia&gt; b0 = res.coeff
16-element Vector{Float64}:
  0.25821563731697006
  0.17173767708354643
  1.1658044162884234
 -0.42146760552733187
  0.01423909223722116
  0.018252219999852187
  1.5429396143493048
 -0.04790078227380377
 -0.21428860376262238
  0.14796117144545648
  1.0418278985865976
  0.02563602493190338
  0.11408617664438392
 -0.22559216646964741
 -1.1399135714873936
 -3.2667147597612805</code></pre><p>The estimation table shown above with the coefficients, standard errors, etc., may also be retrieved using the keyword <code>table</code> (e.g., <code>res.table</code>), though it may not be formatted as pretty.</p><h4 id=".1-hypothesis-testing"><a class="docs-heading-anchor" href="#.1-hypothesis-testing">5.1 hypothesis testing</a><a id=".1-hypothesis-testing-1"></a><a class="docs-heading-anchor-permalink" href="#.1-hypothesis-testing" title="Permalink"></a></h4><p>We may conduct a likelihood ratio (LR) test to see if the data support the frontier specification. The null hypothesis is that the inefficiency term <span>$u_i$</span> is not warranted, and the model&#39;s fit is no better than the OLS.</p><p>First, we calculate the test statistics using the log-likelihood values of the OLS model (keyword <code>OLS_loglikelihood</code>) and the current model (keyword <code>loglikelihood</code>).</p><pre><code class="language-julia hljs">julia&gt; -2*(res.OLS_loglikelihood - res.loglikelihood)  # statistic of the LR test
45.88840046714324</code></pre><p>Because the test amounts to testing <span>$u_i =0$</span> which is on the boundary of the parameter&#39;s support, the appropriate distribution for the test statistic is the mixed <span>$\chi^2$</span> distribution. Critical values may be retrieved using <code>sfmodel_MixTable(dof)</code> where <code>dof</code> is the degree of freedom of the test. In this example, <code>dof=8</code> because there are five parameters involved in <span>$u_i$</span>.</p><pre><code class="language-julia hljs">julia&gt; sfmodel_MixTable(8)   # critical values of the mixed chi^2 test

  * Significance levels and critical values of the mixed ÏÂ² distribution
âââââââ¬âââââââââ¬âââââââââ¬âââââââââ¬âââââââââ
â dof â   0.10 â   0.05 â  0.025 â   0.01 â
âââââââ¼âââââââââ¼âââââââââ¼âââââââââ¼âââââââââ¤
â 8.0 â 12.737 â 14.853 â 16.856 â 19.384 â
âââââââ´âââââââââ´âââââââââ´âââââââââ´âââââââââ

source: Table 1, Kodde and Palm (1986, Econometrica).</code></pre><p>Since the test statistic <span>$45.888$</span> is much larger than the critical value at the <span>$1\%$</span> level (which is <span>$19.384$</span>), the test overwhelmingly rejects the null hypothesis of an OLS model.</p><h4 id=".2-inefficiency-and-efficiency-index"><a class="docs-heading-anchor" href="#.2-inefficiency-and-efficiency-index">5.2 inefficiency and efficiency index</a><a id=".2-inefficiency-and-efficiency-index-1"></a><a class="docs-heading-anchor-permalink" href="#.2-inefficiency-and-efficiency-index" title="Permalink"></a></h4><p>The Jondrow et al. (1982) inefficiency index and the Battese and Coelli (1987) efficiency index at the observation level may also be retrieved using the keywords <code>jlms</code> and <code>bc</code>. Here we show them in a <span>$N\times 2$</span> matrix.</p><pre><code class="language-julia hljs">julia&gt;  [res.jlms  res.bc]   # efficiency and inefficiency index
271Ã2 Matrix{Float64}:
 0.571113  0.574409
 0.510028  0.6102
 0.103925  0.904532
 0.287701  0.758799
 0.151947  0.864143
 0.570984  0.574327
 â®
 1.17586   0.314258
 0.428381  0.662442
 0.847952  0.436286
 0.110013  0.899444
 0.175163  0.845745
 0.165558  0.853443</code></pre><p>Let&#39;s do some graphical presentation on the index using the <a href="http://docs.juliaplots.org/latest/">Plots</a> package. (You may have to add the package by <code>] add Plots</code>.) The following code plots histograms of the index.</p><pre><code class="language-julia hljs">julia&gt; using Plots   # if not installed: `using Pkg; Pkg.add(&quot;Plots&quot;); using Plots`

julia&gt; h1 = histogram(res.jlms, xlabel=&quot;JLMS&quot;, bins=100, label=false)
julia&gt; h2 = histogram(res.bc, xlabel=&quot;BC&quot;, bins=50, label=false)
julia&gt; h1h2= plot(h1, h2, layout = (1,2), legend=false)</code></pre><p><img src="assets/histPlot.svg" alt="histogram"/></p><p>We may save the above figure to the disk for later use. Here we save it in the .svg format as <code>histPlot.svg</code>.</p><pre><code class="language-julia hljs">julia&gt; savefig(h1h2, &quot;histPlot.svg&quot;)  # or .png, .pdf</code></pre><h4 id=".3-marginal-effects"><a class="docs-heading-anchor" href="#.3-marginal-effects">5.3 marginal effects</a><a id=".3-marginal-effects-1"></a><a class="docs-heading-anchor-permalink" href="#.3-marginal-effects" title="Permalink"></a></h4><p>Let&#39;s use the keyword <code>marginal</code> to see the marginal effects of the inefficient determinants on <span>$E(u)$</span> at the observational level, which are saved in the returned dictionary as a <a href="https://dataframes.juliadata.org/stable/">DataFrame</a> object.</p><pre><code class="language-julia hljs">julia&gt; res.marginal  # marginal effects of inefficiency determinants
271Ã3 DataFrame
â Row â marg_age    â marg_school â marg_yr     â
â     â Float64     â Float64     â Float64     â
âââââââ¼ââââââââââââââ¼ââââââââââââââ¼ââââââââââââââ¤
â 1   â -0.00522016 â -0.023474   â -0.0134693  â
â 2   â -0.00636249 â -0.0285745  â -0.00756082 â
â 3   â -0.00775711 â -0.0348048  â -0.00112862 â
â 4   â -0.00953811 â -0.0427643  â 0.00631516  â
â®
â 267 â 0.00211669  â 0.00933601  â -0.0390966  â
â 268 â 0.00291555  â 0.0128358   â -0.0596532  â
â 269 â 0.00221362  â 0.00971877  â -0.0518262  â
â 270 â 0.00160347  â 0.00700978  â -0.0449159  â
â 271 â 0.00107273  â 0.00465371  â -0.0388223  â</code></pre><p>We may also plot the marginal effect.</p><pre><code class="language-julia hljs">julia&gt; m1 = plot(df[:,:age], res.marginal[:,:marg_age], seriestype = :scatter, xlabel = &quot;age&quot;, 
                 ylabel = &quot;marginal effect of age in E(u)&quot;, label = false)
julia&gt; hline!([0.00], label = false)</code></pre><p><img src="assets/margAge.svg" alt="marginaleffect"/></p><p>The plot indicates that production inefficiency decreased (efficiency improved) with age in the early years of the farmerâs life, perhaps because of experience accumulation. But the inefficiency increased with age in later years, perhaps due to deteriorated mental and physical health. Wang&#39;s (2002) model allows the non-monotonic effect to show in the data by parameterizing both of <span>$\mu$</span> and <span>$\sigma_u^2$</span> by the same vector of inefficiency determinants.</p><h4 id=".4-bootstrapping-standard-errors-of-the-mean-marginal-effects"><a class="docs-heading-anchor" href="#.4-bootstrapping-standard-errors-of-the-mean-marginal-effects">5.4 bootstrapping standard errors of the mean marginal effects</a><a id=".4-bootstrapping-standard-errors-of-the-mean-marginal-effects-1"></a><a class="docs-heading-anchor-permalink" href="#.4-bootstrapping-standard-errors-of-the-mean-marginal-effects" title="Permalink"></a></h4><p><code>sfmodel_fit()</code> calculates the means of the marginal effects and the values are reported in the printout: <code>* The sample mean of inefficiency determinants&#39; marginal effects on E(u): (age = -0.00264, school = -0.01197, yr = -0.0265)</code>. We may bootstrap the standard errors of the mean marginal effects using <code>sfmodel_boot_marginal()</code>.  As a demonstration, in this example we use only 100 bootstrapped samples (<code>R=100</code>) and restrict the iteration number to be 100 (<code>iter=100</code>) to calculate the standard errors.</p><pre><code class="language-julia hljs">julia&gt; sfmodel_boot_marginal(result=res, data=df, R=100, seed=1232, iter=100) # bootstrap std.err.
bootstrap in progress..10..20..30..40..50..60..70..80..90..100..Done!

ââââââââââ¬âââââââââââââââââââââââ¬âââââââââââââââââââââââ
â        â mean of the marginal â      std.err. of the â
â        â       effect on E(u) â mean marginal effect â
ââââââââââ¼âââââââââââââââââââââââ¼âââââââââââââââââââââââ¤
â    age â            -0.002645 â               0.0020 â
â school â           -0.0119745 â               0.0121 â
â     yr â           -0.0265006 â               0.0122 â
ââââââââââ´âââââââââââââââââââââââ´âââââââââââââââââââââââ

3Ã1 adjoint(::Matrix{Float64}) with eltype Float64:
 0.00203219086278005
 0.01211790227397574
 0.012241964814735964</code></pre><ul><li><code>result=</code>res: The returned result from <code>sfmodel_fit()</code> from the main estimation (in our example, <code>res</code>).</li><li><code>data=</code>df: The dataset (in DataFrame format) used in <code>sfmodel_fit()</code>. If data was supplied using matrix (i.e., the Method 2 of <code>sfmodel_spec()</code>), this option should be skipped.</li><li><code>R=</code>250: The number of bootstrapped samples.</li><li><code>seed=</code>1232: Optional. A positive integer used as the seed for a random number generator in resampling, which ensures reproducibility. If not specified, the global random number generator is used, and the bootstrap result may change (slightly) between runs.</li><li><code>iter=</code>100: The iteration limit for each of the maximum likelihood estimation. The default is the one specified by <code>main_maxIT()</code> in <code>sfmodel_opt()</code>.</li></ul><p>See help on <code>sfmodel_boot_marginal</code> for other options.</p><p>The <span>$3\times 1$</span> vector of the bootstrapped standard errors is now saved in <code>b_err</code>. The entire bootstrapped data of size <span>$R \times 3$</span> can also be made available for later analysis via the option <code>getBootData=true</code>. Each row of the data contains the bootstrapped statistics (in this example, there are three) from one sample.</p><h4 id=".5-predicted-values-of-equations"><a class="docs-heading-anchor" href="#.5-predicted-values-of-equations">5.5 predicted values of equations</a><a id=".5-predicted-values-of-equations-1"></a><a class="docs-heading-anchor-permalink" href="#.5-predicted-values-of-equations" title="Permalink"></a></h4><p><strong>SFrontiers</strong> provides the function <code>sfmodel_predict()</code> to obtain predicted values of model equations after the model is estimated. The following example returns the predicted value of the <code>frontier</code> equation, i.e., <span>$\mathbf{x} \hat{\beta}$</span>.</p><pre><code class="language-julia hljs">julia&gt; xb = sfmodel_predict(@eq(frontier), df)   # predict equation `frontier`
271-element Vector{Float64}:
 5.870910806585876
 5.491526404276636
 5.162700470230824
 5.5235030982431805
 6.112704105091019
 6.0987515622992206
 â®
 4.916534395720751
 6.418237370122121
 8.208785623085882
 7.895417236187299
 8.549405592214674
 6.399603902768199</code></pre><p>Note that <code>df</code> in the function is the name of the DataFrame which we had used to estimate the model. If <a href="ex_detail.html#matrixinput">matrix and vectors are used as data input</a>, the argument can be skipped. The estimated composed error of the model, namely <span>$\hat{\epsilon}_i = \hat{v}_i - \hat{u}_i$</span>, is then obtained by <code>df[:, :yvar] - xb</code>.</p><p>Predicted values of other equations may be obtain in the similar way. For instance, <code>sfmodel_predict(@eq( Ïáµ¤Â² ),df)</code>.</p><h3 id=".-save-results-to-disk"><a class="docs-heading-anchor" href="#.-save-results-to-disk">6. save results to disk</a><a id=".-save-results-to-disk-1"></a><a class="docs-heading-anchor-permalink" href="#.-save-results-to-disk" title="Permalink"></a></h3><p>We may save the entire <code>res</code> dictionary or part of the results to the disk and load them later in other sessions for further analysis. There are several ways to do this. One is to save the dictionary in a binary file. Here we use the <a href="https://juliaio.github.io/JLD2.jl/stable/">JLD2</a> package to save it in the HDF5 format.</p><pre><code class="language-julia hljs">julia&gt; using JLD2    # which saves objects in HDF5-based Julia Data Format

julia&gt; save_object(&quot;model1.jld2&quot;, res)       # save `res` dictionary to `model1.jld2`
julia&gt; result1 = load_object(&quot;model1.jld2&quot;)  # load it back to `result1`

julia&gt; save_object(&quot;model1_jlms.jld2&quot;, res.jlms)    # save only the JLMS inefficiency index
julia&gt; jlmsindex = load_object(&quot;model1_jlms.jld2&quot;)  # load it back to `jlmsindex`</code></pre><p>It is also possible to save some of the results in the good old text format which is cross-platform, version compatible, human-readable, and likely superior for the purpose of long-term storage. Here we use <code>CSV.write()</code> function from the <a href="https://csv.juliadata.org/stable/#CSV.write">CSV</a> package that we have loaded earlier. A limitation of the function is that it only saves table-like or matrix-like data. We may not save the entire <code>res</code> dictionary with it. </p><pre><code class="language-julia hljs">julia&gt; CSV.write(&quot;marginal.txt&quot;, DataFrame(res.marginal, :auto), header=true)  # save the marginal effects to `marginal.txt`

julia&gt; CSV.write(&quot;coeff.txt&quot;, 
                 DataFrame(reshape(res.coeff, length(res.coeff), 1), :auto), 
                 header=true)              # save the coefficient vector to `coeff.txt`</code></pre><p>Because <code>res.coeff</code> is a vector, it has to be converted into a matrix to use <code>CSV.write</code>. The <code>reshape()</code> bit is used for this purpose.</p><h5 id="You-may-also-download-the-data-and-the-example-as-a-Jupyter-notebook-[in-a-zip-file](detailed_example.zip).-2"><a class="docs-heading-anchor" href="#You-may-also-download-the-data-and-the-example-as-a-Jupyter-notebook-[in-a-zip-file](detailed_example.zip).-2">You may also download the data and the example as a Jupyter notebook <a href="detailed_example.zip">in a zip file</a>.</a><a class="docs-heading-anchor-permalink" href="#You-may-also-download-the-data-and-the-example-as-a-Jupyter-notebook-[in-a-zip-file](detailed_example.zip).-2" title="Permalink"></a></h5></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="overview.html">Â« Estimation Overview</a><a class="docs-footer-nextpage" href="ex_cross.html">cross-sectional models Â»</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.5 on <span class="colophon-date" title="Saturday 28 August 2021 23:39">Saturday 28 August 2021</span>. Using Julia version 1.6.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
